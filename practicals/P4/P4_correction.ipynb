{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3db6482b",
      "metadata": {
        "id": "3db6482b"
      },
      "source": [
        "\n",
        "# Practical session n°4 :\n",
        "\n",
        "Notions:\n",
        "\n",
        "\n",
        "*   Attentional layers\n",
        "*   Multiple attentional heads\n",
        "*   Standard toy tasks (Dyck validaty test, addition, parity test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc8d855",
      "metadata": {
        "id": "2bc8d855"
      },
      "source": [
        "## Part I — Presentation of the Transformer architecture\n",
        "\n",
        "In this part, you will:\n",
        "\n",
        "1. See how a tiny Transformer is coded in PyTorch.\n",
        "2. Focus on the attention layer: multi-head mechanism and the role of the Q, K, V matrices.\n",
        "3. Estimate how many FLOPs are involved in a forward pass through a multi-head attention layer  \n",
        "   (and compare with the theoretical considerations from the lesson).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & basic configuration\n",
        "\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(precision=4, sci_mode=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZagGANXs-hI",
        "outputId": "f398bf97-4c16-4c4a-c404-e57bb0751c9e"
      },
      "id": "fZagGANXs-hI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny Transformer building blocks (embedding + multi-head attention)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 1024):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
        "            * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, D)\n",
        "        L = x.size(1)\n",
        "        return x + self.pe[:, :L, :]\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Minimal multi-head self-attention.\n",
        "    If verbose=True, prints tensor shapes at key steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int = 64, n_heads: int = 4, verbose: bool = False):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_head = d_model // n_heads\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.Wq = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wk = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wv = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wo = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def _vprint(self, name, x):\n",
        "        if self.verbose:\n",
        "            print(f\"{name}: {tuple(x.shape)}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, D)\n",
        "        B, L, D = x.shape\n",
        "\n",
        "        Q = self.Wq(x)  # (B, L, D)\n",
        "        K = self.Wk(x)\n",
        "        V = self.Wv(x)\n",
        "        self._vprint(\"Q\", Q)\n",
        "        self._vprint(\"K\", K)\n",
        "        self._vprint(\"V\", V)\n",
        "\n",
        "        # reshape to heads\n",
        "        Q = Q.view(B, L, self.n_heads, self.d_head).transpose(1, 2)  # (B, H, L, Dh)\n",
        "        K = K.view(B, L, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        V = V.view(B, L, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        self._vprint(\"Q_heads\", Q)\n",
        "        self._vprint(\"K_heads\", K)\n",
        "        self._vprint(\"V_heads\", V)\n",
        "\n",
        "        # scaled dot-product attention\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_head)  # (B,H,L,L)\n",
        "        self._vprint(\"scores\", scores)\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)  # (B,H,L,L)\n",
        "        self._vprint(\"attn_probs\", attn)\n",
        "\n",
        "        Z = torch.matmul(attn, V)  # (B,H,L,Dh)\n",
        "        self._vprint(\"Z_heads\", Z)\n",
        "\n",
        "        # merge heads\n",
        "        Z = Z.transpose(1, 2).contiguous().view(B, L, D)  # (B, L, D)\n",
        "        self._vprint(\"Z_merged\", Z)\n",
        "\n",
        "        out = self.Wo(Z)  # (B, L, D)\n",
        "        self._vprint(\"out\", out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model: int = 64, n_heads: int = 4, mlp_ratio: int = 4):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadSelfAttention(d_model=d_model, n_heads=n_heads, verbose=False)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * mlp_ratio),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_model * mlp_ratio, d_model),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class TinyTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Tiny Transformer for sequence classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int, d_model: int = 64, n_heads: int = 4, n_layers: int = 2, num_classes: int = 2):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding(d_model)\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [TransformerBlock(d_model=d_model, n_heads=n_heads) for _ in range(n_layers)]\n",
        "        )\n",
        "        self.head = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L) token ids\n",
        "        h = self.tok_emb(x)\n",
        "        h = self.pos_emb(h)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        # use mean pooling for classification\n",
        "        h = h.mean(dim=1)\n",
        "        return self.head(h)\n"
      ],
      "metadata": {
        "id": "N_ikSjeMtBUt"
      },
      "id": "N_ikSjeMtBUt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 1 — Check embedding output size\n",
        "\n",
        "Using `TinyTransformer`, define a random input batch of token ids with:\n",
        "\n",
        "- batch size `B`\n",
        "- sequence length `L`\n",
        "- vocabulary size consistent with the model\n",
        "\n",
        "Use `torch.randint` to generate this input and pass it **only through the embedding layer**.  \n",
        "Verify that the output has shape `(B, L, d_model)`."
      ],
      "metadata": {
        "id": "TgJt9nGgtUcs"
      },
      "id": "TgJt9nGgtUcs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Correction Exercice 1\n",
        "\n",
        "B, L = 4, 10\n",
        "vocab_size = 20\n",
        "d_model = 64\n",
        "\n",
        "model = TinyTransformer(vocab_size=vocab_size, d_model=d_model, n_heads=4, n_layers=2, num_classes=2)\n",
        "\n",
        "x = torch.randint(low=0, high=vocab_size, size=(B, L))  # (B, L)\n",
        "with torch.no_grad():\n",
        "    emb_out = model.tok_emb(x)  # (B, L, d_model)\n",
        "\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Embedding output shape:\", emb_out.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "mhgeyjsitI6p",
        "outputId": "f0a664b4-1ef4-45b9-8983-767003230af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mhgeyjsitI6p",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 10])\n",
            "Embedding output shape: torch.Size([4, 10, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 2 — Pass through MultiHeadSelfAttention (with verbose shapes)\n",
        "\n",
        "1. Reuse the embedded tensor from Exercice 1 (or recreate it).\n",
        "2. Instantiate a `MultiHeadSelfAttention` layer with `verbose=True`.\n",
        "3. Pass the embeddings through it and observe the printed shapes at each step.\n",
        "\n",
        "This is to **trace Q, K, V, heads, scores, and outputs**.\n"
      ],
      "metadata": {
        "id": "cPcdxu-CtgEh"
      },
      "id": "cPcdxu-CtgEh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Correction Exercice 2\n",
        "\n",
        "B, L = 2, 6\n",
        "vocab_size = 20\n",
        "d_model = 64\n",
        "n_heads = 4\n",
        "\n",
        "x = torch.randint(0, vocab_size, (B, L))\n",
        "emb = model.tok_emb(x)\n",
        "\n",
        "attn = MultiHeadSelfAttention(d_model=d_model, n_heads=n_heads, verbose=True)\n",
        "with torch.no_grad():\n",
        "    out = attn(emb)\n",
        "\n",
        "print(\"Final attention output shape:\", out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGzvX2I0tSVM",
        "outputId": "b96df7af-b816-4fde-f929-b0aea55efdc9"
      },
      "id": "lGzvX2I0tSVM",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: (2, 6, 64)\n",
            "K: (2, 6, 64)\n",
            "V: (2, 6, 64)\n",
            "Q_heads: (2, 4, 6, 16)\n",
            "K_heads: (2, 4, 6, 16)\n",
            "V_heads: (2, 4, 6, 16)\n",
            "scores: (2, 4, 6, 6)\n",
            "attn_probs: (2, 4, 6, 6)\n",
            "Z_heads: (2, 4, 6, 16)\n",
            "Z_merged: (2, 6, 64)\n",
            "out: (2, 6, 64)\n",
            "Final attention output shape: torch.Size([2, 6, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 3 — Count FLOPs in multi-head self-attention\n",
        "\n",
        "For a single multi-head self-attention layer with:\n",
        "\n",
        "- sequence length `L`\n",
        "- model dimension `d_model`\n",
        "- number of heads `h` (each of size `d_head = d_model / h`)\n",
        "\n",
        "1. Derive the approximate number of multiply-add operations for:\n",
        "   - Q, K, V linear projections\n",
        "   - Attention scores computation\n",
        "   - Attention-weighted sum\n",
        "   - Output projection\n",
        "2. Identify the term that dominates when `L` is large, and explain why it is in `O(L² × d_model)`.\n",
        "\n",
        "Complete the function below.\n"
      ],
      "metadata": {
        "id": "7K_D-zOFtvlx"
      },
      "id": "7K_D-zOFtvlx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Correction Exercice 3 & 4 — FLOPs estimates\n",
        "\n",
        "def mhsa_flops(L, d_model, n_heads):\n",
        "    \"\"\"\n",
        "    Rough FLOPs (multiply-adds counted as ~2 ops, but we keep a simple count).\n",
        "    Returns a dict with contributions.\n",
        "    \"\"\"\n",
        "    d_head = d_model // n_heads\n",
        "\n",
        "    # Q, K, V projections: 3 * (L * d_model * d_model)\n",
        "    qkv = 3 * L * d_model * d_model\n",
        "\n",
        "    # scores = Q K^T: (B,H,L,Dh) x (B,H,Dh,L) -> (B,H,L,L)\n",
        "    # ~ 2 * (H * L * L * Dh)\n",
        "    scores = 2 * n_heads * (L * L * d_head)\n",
        "\n",
        "    # attn @ V: (B,H,L,L) x (B,H,L,Dh) -> (B,H,L,Dh)\n",
        "    # ~ 2 * (H * L * L * Dh)\n",
        "    weighted = 2 * n_heads * (L * L * d_head)\n",
        "\n",
        "    # output projection Wo: L * d_model * d_model\n",
        "    wo = L * d_model * d_model\n",
        "\n",
        "    return {\n",
        "        \"qkv\": qkv,\n",
        "        \"scores\": scores,\n",
        "        \"weighted\": weighted,\n",
        "        \"wo\": wo,\n",
        "        \"total\": qkv + scores + weighted + wo,\n",
        "    }\n",
        "\n",
        "# Example: impact of L (show domination of L^2 * d_model terms)\n",
        "for L in [16, 64, 256]:\n",
        "    stats = mhsa_flops(L=L, d_model=64, n_heads=4)\n",
        "    print(f\"L={L} -> total={stats['total']:.2e}, scores+weighted={stats['scores']+stats['weighted']:.2e}\")\n",
        "\n",
        "print(\"\\nObservation: for large L, the attention matrix computations (in L^2) dominate.\")\n",
        "\n",
        "# Exercice 4 — Example: FLOPs for a tiny Transformer on a batch\n",
        "def tiny_transformer_flops(num_layers, L, d_model, n_heads, mlp_ratio=4):\n",
        "    attn = mhsa_flops(L, d_model, n_heads)[\"total\"]\n",
        "    # MLP per layer: 2 linear layers: ~ 2 * L * d_model * (d_model * mlp_ratio)\n",
        "    mlp = 2 * L * d_model * (d_model * mlp_ratio)\n",
        "    per_layer = attn + mlp\n",
        "    return num_layers * per_layer\n",
        "\n",
        "print(\"\\nTinyTransformer example (num_layers=2, L=64, d_model=64, n_heads=4):\")\n",
        "print(f\"~ {tiny_transformer_flops(2, 64, 64, 4):.2e} FLOPs (rough order of magnitude)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQL1gdEPt3rH",
        "outputId": "dbe0c236-4867-43b2-e605-4a891edd12c3"
      },
      "id": "TQL1gdEPt3rH",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L=16 -> total=3.28e+05, scores+weighted=6.55e+04\n",
            "L=64 -> total=2.10e+06, scores+weighted=1.05e+06\n",
            "L=256 -> total=2.10e+07, scores+weighted=1.68e+07\n",
            "\n",
            "Observation: for large L, the attention matrix computations (in L^2) dominate.\n",
            "\n",
            "TinyTransformer example (num_layers=2, L=64, d_model=64, n_heads=4):\n",
            "~ 8.39e+06 FLOPs (rough order of magnitude)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II — A first example: Validation of Dyck-1 words\n",
        "\n",
        "We now train models to decide if a word over `{ '(', ')' }` is a valid Dyck-1 word (balanced parentheses).\n",
        "\n",
        "We start with a simple dataset **without distractors**.\n"
      ],
      "metadata": {
        "id": "v335uURwuFUX"
      },
      "id": "v335uURwuFUX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Dyck-1 dataset (no distractors)\n",
        "\n",
        "VOCAB_DYCK = ['(', ')']\n",
        "stoi_dyck = {c: i for i, c in enumerate(VOCAB_DYCK)}\n",
        "itos_dyck = {i: c for c, i in stoi_dyck.items()}\n",
        "\n",
        "def dyck1_valid_sequence(n_pairs):\n",
        "    \"\"\"\n",
        "    Generate a uniformly random valid Dyck-1 sequence with n_pairs pairs.\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    depth = 0\n",
        "    for _ in range(2 * n_pairs):\n",
        "        if depth == 0:\n",
        "            seq.append('(')\n",
        "            depth += 1\n",
        "        elif depth == (2 * n_pairs - len(seq)):\n",
        "            seq.append(')')\n",
        "            depth -= 1\n",
        "        else:\n",
        "            if random.random() < 0.5:\n",
        "                seq.append('(')\n",
        "                depth += 1\n",
        "            else:\n",
        "                seq.append(')')\n",
        "                depth -= 1\n",
        "    return ''.join(seq)\n",
        "\n",
        "def is_valid_dyck1(s):\n",
        "    depth = 0\n",
        "    for ch in s:\n",
        "        if ch == '(':\n",
        "            depth += 1\n",
        "        elif ch == ')':\n",
        "            depth -= 1\n",
        "        if depth < 0:\n",
        "            return False\n",
        "    return depth == 0\n",
        "\n",
        "class DyckDataset(nn.Module):\n",
        "    \"\"\"\n",
        "    Binary classification:\n",
        "    y = 1 if valid Dyck-1, y = 0 otherwise.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_samples=2000, n_pairs=6):\n",
        "        super().__init__()\n",
        "        self.samples = []\n",
        "        for _ in range(n_samples):\n",
        "            s = dyck1_valid_sequence(n_pairs)\n",
        "            # with prob 0.5 corrupt one char to create invalid string\n",
        "            if random.random() < 0.5:\n",
        "                y = 1\n",
        "            else:\n",
        "                s = list(s)\n",
        "                pos = random.randrange(len(s))\n",
        "                s[pos] = '(' if s[pos] == ')' else ')'\n",
        "                s = ''.join(s)\n",
        "                y = int(is_valid_dyck1(s))\n",
        "                # if by chance it is valid, flip again\n",
        "                if y == 1:\n",
        "                    pos = (pos + 1) % len(s)\n",
        "                    s = list(s)\n",
        "                    s[pos] = '(' if s[pos] == ')' else ')'\n",
        "                    s = ''.join(s)\n",
        "                    y = int(is_valid_dyck1(s))\n",
        "            x = torch.tensor([stoi_dyck[c] for c in s], dtype=torch.long)\n",
        "            self.samples.append((x, torch.tensor(y, dtype=torch.long)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "def dyck_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    L = max(len(x) for x in xs)\n",
        "    X = torch.full((len(xs), L), fill_value=0, dtype=torch.long)\n",
        "    for i, x in enumerate(xs):\n",
        "        X[i, :len(x)] = x\n",
        "    Y = torch.stack(ys)\n",
        "    return X, Y\n"
      ],
      "metadata": {
        "id": "TN2FJTOGuLYY"
      },
      "id": "TN2FJTOGuLYY",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 5 — Inspect Dyck-1 samples\n",
        "\n",
        "1. Build a `DyckDataset` with `n_pairs = 6`.\n",
        "2. Print the first 5 sequences:\n",
        "   - as indices\n",
        "   - as corresponding parenthesis strings\n",
        "   - with their labels (valid / invalid)\n",
        "3. What is the size of the vocabulary for this problem?\n"
      ],
      "metadata": {
        "id": "qGyMFcCeunqR"
      },
      "id": "qGyMFcCeunqR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Correction Exercice 5\n",
        "\n",
        "dyck_train = DyckDataset(n_samples=8, n_pairs=6)\n",
        "\n",
        "for i in range(5):\n",
        "    x, y = dyck_train[i]\n",
        "    s = ''.join(itos_dyck[int(t)] for t in x)\n",
        "    print(f\"Sample {i}: indices={x.tolist()}  | word={s}  | label={int(y)}\")\n",
        "\n",
        "print(\"\\nVocabulary:\", VOCAB_DYCK)\n",
        "print(\"Vocab size:\", len(VOCAB_DYCK))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEkcsYYKupbc",
        "outputId": "b1ddda09-2e0a-4c04-eac8-f9827888e6b4"
      },
      "id": "OEkcsYYKupbc",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0: indices=[0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1]  | word=()())(()()))  | label=0\n",
            "Sample 1: indices=[0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]  | word=()(()((())))  | label=1\n",
            "Sample 2: indices=[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  | word=()()()()()()  | label=1\n",
            "Sample 3: indices=[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1]  | word=((((()(())))  | label=0\n",
            "Sample 4: indices=[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]  | word=()(()(()(())  | label=0\n",
            "\n",
            "Vocabulary: ['(', ')']\n",
            "Vocab size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 6 — Training loop with history + learning curves\n",
        "\n",
        "Complete a training loop that:\n",
        "\n",
        "1. Trains a small Transformer on Dyck-1.\n",
        "2. Stores training and validation accuracies at each epoch.\n",
        "3. Plots both curves on the same figure.\n",
        "\n",
        "Use the `TinyTransformer` from Part I (with `vocab_size = 2`).\n"
      ],
      "metadata": {
        "id": "hBv9HwK0uwXl"
      },
      "id": "hBv9HwK0uwXl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training utilities (Transformer on Dyck-1) with history\n",
        "\n",
        "def accuracy_from_logits(logits, y):\n",
        "    return (logits.argmax(dim=-1) == y).float().mean().item()\n",
        "\n",
        "def train_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "    for X, Y in loader:\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X)\n",
        "        loss = F.cross_entropy(logits, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        bs = X.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += accuracy_from_logits(logits, Y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "    for X, Y in loader:\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        logits = model(X)\n",
        "        loss = F.cross_entropy(logits, Y)\n",
        "        bs = X.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += accuracy_from_logits(logits, Y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_acc / n\n"
      ],
      "metadata": {
        "id": "U76FkXdku1XZ"
      },
      "id": "U76FkXdku1XZ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Transformer on Dyck-1 and plot curves\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = DyckDataset(n_samples=2000, n_pairs=6)\n",
        "val_set   = DyckDataset(n_samples=500,  n_pairs=6)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_set,   batch_size=64, shuffle=False)\n",
        "\n",
        "model_tx = TinyTransformer(vocab_size=len(VOCAB_DYCK), d_model=64, n_heads=4, n_layers=2, num_classes=2).to(device)\n",
        "opt = torch.optim.AdamW(model_tx.parameters(), lr=2e-3)\n",
        "\n",
        "E = 8\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(1, E+1):\n",
        "    tr_loss, tr_acc = train_epoch(model_tx, train_loader, opt)\n",
        "    va_loss, va_acc = eval_epoch(model_tx, val_loader)\n",
        "    train_accs.append(tr_acc)\n",
        "    val_accs.append(va_acc)\n",
        "    print(f\"Epoch {epoch}: train_acc={tr_acc:.3f}, val_acc={va_acc:.3f}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, E+1), train_accs, label=\"train\")\n",
        "plt.plot(range(1, E+1), val_accs, label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Dyck-1 — TinyTransformer\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hct-feEqu5fN",
        "outputId": "84bf2d19-c7fb-48ca-951b-3bccc1b9da8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "id": "Hct-feEqu5fN",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_acc=0.518, val_acc=0.500\n",
            "Epoch 2: train_acc=0.488, val_acc=0.768\n",
            "Epoch 3: train_acc=0.857, val_acc=1.000\n",
            "Epoch 4: train_acc=1.000, val_acc=1.000\n",
            "Epoch 5: train_acc=1.000, val_acc=1.000\n",
            "Epoch 6: train_acc=1.000, val_acc=1.000\n",
            "Epoch 7: train_acc=1.000, val_acc=1.000\n",
            "Epoch 8: train_acc=1.000, val_acc=1.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mots = [\"((()()))\", \"()()((()))\", \"(()))\",\"(\",\"()()()()()()()()()()()()()\",\"(()\",\"()()()()())((()())\"]\n",
        "for mot in mots:\n",
        "  x = torch.tensor([stoi_dyck[c] for c in mot], dtype=torch.long)\n",
        "  output = model_tx(x.unsqueeze(0).to(device))\n",
        "  print(output)\n",
        "  print(output.argmax(dim=-1))\n",
        "\n",
        "# il a faux sur le dernier mot"
      ],
      "metadata": {
        "id": "XFXw0QMBgCBU",
        "outputId": "a68d5ad5-acb0-46d6-f696-8580f5431a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XFXw0QMBgCBU",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-5.6118,  8.5666]], grad_fn=<AddmmBackward0>)\n",
            "tensor([1])\n",
            "tensor([[-6.1811,  9.6582]], grad_fn=<AddmmBackward0>)\n",
            "tensor([1])\n",
            "tensor([[ 4.6989, -9.9781]], grad_fn=<AddmmBackward0>)\n",
            "tensor([0])\n",
            "tensor([[ 13.2564, -20.3090]], grad_fn=<AddmmBackward0>)\n",
            "tensor([0])\n",
            "tensor([[-5.1196,  7.7586]], grad_fn=<AddmmBackward0>)\n",
            "tensor([1])\n",
            "tensor([[ 10.4819, -16.4210]], grad_fn=<AddmmBackward0>)\n",
            "tensor([0])\n",
            "tensor([[-4.6834,  7.2465]], grad_fn=<AddmmBackward0>)\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 7 — Compare with a CNN baseline\n",
        "\n",
        "1. Implement a 1D CNN below.\n",
        "2. Train it on the same Dyck-1 dataset.\n",
        "3. Compare its validation accuracy and behavior with the Transformer.\n",
        "\n",
        "Use the correction cell below only after you have tried.\n"
      ],
      "metadata": {
        "id": "hnDzwsjxvIpI"
      },
      "id": "hnDzwsjxvIpI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Correction Exercice 7 — Simple CNN baseline on Dyck-1\n",
        "\n",
        "class DyckCNN(nn.Module):\n",
        "    def __init__(self, vocab_size=2, emb_dim=32, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.conv1 = nn.Conv1d(emb_dim, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.head = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L)\n",
        "        e = self.emb(x).transpose(1, 2)  # (B,C,L)\n",
        "        h = F.relu(self.conv1(e))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = h.mean(dim=-1)               # global average pooling\n",
        "        return self.head(h)\n",
        "\n",
        "cnn = DyckCNN(vocab_size=len(VOCAB_DYCK), emb_dim=32, num_classes=2).to(device)\n",
        "opt_cnn = torch.optim.AdamW(cnn.parameters(), lr=2e-3)\n",
        "\n",
        "E = 8\n",
        "for epoch in range(1, E+1):\n",
        "    tr_loss, tr_acc = train_epoch(cnn, train_loader, opt_cnn)\n",
        "    va_loss, va_acc = eval_epoch(cnn, val_loader)\n",
        "    print(f\"[CNN] Epoch {epoch}: train_acc={tr_acc:.3f}, val_acc={va_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "Y-aVL-3VvIC9",
        "outputId": "ef5d4516-2e2e-4467-cc33-5fcaa8f21b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Y-aVL-3VvIC9",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CNN] Epoch 1: train_acc=0.516, val_acc=0.618\n",
            "[CNN] Epoch 2: train_acc=0.537, val_acc=0.500\n",
            "[CNN] Epoch 3: train_acc=0.543, val_acc=0.598\n",
            "[CNN] Epoch 4: train_acc=0.574, val_acc=0.622\n",
            "[CNN] Epoch 5: train_acc=0.606, val_acc=0.640\n",
            "[CNN] Epoch 6: train_acc=0.625, val_acc=0.678\n",
            "[CNN] Epoch 7: train_acc=0.632, val_acc=0.660\n",
            "[CNN] Epoch 8: train_acc=0.640, val_acc=0.614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part III — Addition and Parity tasks\n",
        "\n",
        "### Exercice 11\n",
        "\n",
        "Use the following synthetic datasets to train and compare models\n",
        "(Transformers and CNNs) on:\n",
        "\n",
        "1. **Addition**: predict the last digit of `a + b` from an input like `\"123+45=\"`.\n",
        "2. **Parity**: predict the parity (0/1) of a binary string.\n",
        "\n",
        "Reuse your training utilities from Part II.\n"
      ],
      "metadata": {
        "id": "dL_O3f55vTXv"
      },
      "id": "dL_O3f55vTXv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Addition & Parity datasets\n",
        "\n",
        "# --- Addition ---\n",
        "DIGITS = [str(i) for i in range(10)]\n",
        "ADD_VOCAB = DIGITS + ['+', '=']\n",
        "add_stoi = {c: i for i, c in enumerate(ADD_VOCAB)}\n",
        "\n",
        "def gen_add_sample(n1_digits=3, n2_digits=3):\n",
        "    \"\"\"\n",
        "    Input:  string representation \"a+b=\".\n",
        "    Target: last digit of (a + b).\n",
        "    \"\"\"\n",
        "    a = random.randint(0, 10**n1_digits - 1)\n",
        "    b = random.randint(0, 10**n2_digits - 1)\n",
        "    s = f\"{a}+{b}=\"\n",
        "    x = torch.tensor([add_stoi[c] for c in s], dtype=torch.long)\n",
        "    y = (a + b) % 10\n",
        "    return x, torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class AddDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, n, n1_digits=3, n2_digits=3):\n",
        "        self.samples = [gen_add_sample(n1_digits, n2_digits) for _ in range(n)]\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i): return self.samples[i]\n",
        "\n",
        "def add_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    L = max(len(x) for x in xs)\n",
        "    X = torch.full((len(xs), L), fill_value=0, dtype=torch.long)\n",
        "    for i, x in enumerate(xs):\n",
        "        X[i, :len(x)] = x\n",
        "    Y = torch.stack(ys)\n",
        "    return X, Y\n",
        "\n",
        "# --- Parity ---\n",
        "BIN_VOCAB = ['0', '1']\n",
        "bin_stoi = {c: i for i, c in enumerate(BIN_VOCAB)}\n",
        "\n",
        "def gen_parity_sample(L=32):\n",
        "    \"\"\"\n",
        "    Input:  random binary string of length L.\n",
        "    Target: parity of number of '1's (0 = even, 1 = odd).\n",
        "    \"\"\"\n",
        "    s = ''.join(random.choice(BIN_VOCAB) for _ in range(L))\n",
        "    x = torch.tensor([bin_stoi[c] for c in s], dtype=torch.long)\n",
        "    y = s.count('1') % 2\n",
        "    return x, torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class ParityDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, n, L=32):\n",
        "        self.samples = [gen_parity_sample(L) for _ in range(n)]\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i): return self.samples[i]\n",
        "\n",
        "def parity_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    L = max(len(x) for x in xs)\n",
        "    X = torch.full((len(xs), L), fill_value=0, dtype=torch.long)\n",
        "    for i, x in enumerate(xs):\n",
        "        X[i, :len(x)] = x\n",
        "    Y = torch.stack(ys)\n",
        "    return X, Y\n"
      ],
      "metadata": {
        "id": "HjFRFST-vWzS"
      },
      "id": "HjFRFST-vWzS",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reusable training helper (supports different num_classes)\n",
        "\n",
        "def train_model_classifier(model, train_loader, val_loader, epochs=6, lr=2e-3, name=\"model\"):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    best_val = 0.0\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        tr_loss, tr_acc = train_epoch(model, train_loader, opt)\n",
        "        va_loss, va_acc = eval_epoch(model, val_loader)\n",
        "        if va_acc > best_val:\n",
        "            best_val = va_acc\n",
        "        print(f\"[{name}] Epoch {ep}: train_acc={tr_acc:.3f}, val_acc={va_acc:.3f}\")\n",
        "    print(f\"[{name}] best_val_acc={best_val:.3f}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "l77JtPjXvcbK"
      },
      "id": "l77JtPjXvcbK",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join([ADD_VOCAB[x.item()] for x in train_add[0][0]])"
      ],
      "metadata": {
        "id": "4CskfFWekcVK",
        "outputId": "d2867da4-d18e-4e63-e15c-54946f00fb95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "4CskfFWekcVK",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'346+859='"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: TinyTransformer on Addition & Parity\n",
        "\n",
        "# Addition\n",
        "train_add = AddDataset(n=4000)\n",
        "val_add   = AddDataset(n=1000)\n",
        "\n",
        "train_add_loader = torch.utils.data.DataLoader(train_add, batch_size=64, shuffle=True,  collate_fn=add_collate)\n",
        "val_add_loader   = torch.utils.data.DataLoader(val_add,   batch_size=64, shuffle=False, collate_fn=add_collate)\n",
        "\n",
        "tx_add = TinyTransformer(vocab_size=len(ADD_VOCAB), d_model=64, n_heads=4, n_layers=2, num_classes=10)\n",
        "train_model_classifier(tx_add, train_add_loader, val_add_loader, epochs=6, name=\"Transformer-Add\")\n",
        "\n",
        "# Parity\n",
        "train_par = ParityDataset(n=4000, L=64)\n",
        "val_par   = ParityDataset(n=1000, L=64)\n",
        "\n",
        "train_par_loader = torch.utils.data.DataLoader(train_par, batch_size=64, shuffle=True,  collate_fn=parity_collate)\n",
        "val_par_loader   = torch.utils.data.DataLoader(val_par,   batch_size=64, shuffle=False, collate_fn=parity_collate)\n",
        "\n",
        "tx_par = TinyTransformer(vocab_size=len(BIN_VOCAB), d_model=64, n_heads=4, n_layers=2, num_classes=2)\n",
        "train_model_classifier(tx_par, train_par_loader, val_par_loader, epochs=300, lr=2e-4, name=\"Transformer-Parity\")\n"
      ],
      "metadata": {
        "id": "dVUFh8pxvgkd",
        "outputId": "83b17bfc-8160-498a-f6dc-2c132d983f4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dVUFh8pxvgkd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Transformer-Add] Epoch 1: train_acc=0.104, val_acc=0.096\n",
            "[Transformer-Add] Epoch 2: train_acc=0.127, val_acc=0.117\n",
            "[Transformer-Add] Epoch 3: train_acc=0.161, val_acc=0.168\n",
            "[Transformer-Add] Epoch 4: train_acc=0.205, val_acc=0.205\n",
            "[Transformer-Add] Epoch 5: train_acc=0.397, val_acc=0.601\n",
            "[Transformer-Add] Epoch 6: train_acc=0.753, val_acc=0.835\n",
            "[Transformer-Add] best_val_acc=0.835\n",
            "[Transformer-Parity] Epoch 1: train_acc=0.502, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 2: train_acc=0.499, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 3: train_acc=0.505, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 4: train_acc=0.498, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 5: train_acc=0.508, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 6: train_acc=0.501, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 7: train_acc=0.500, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 8: train_acc=0.511, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 9: train_acc=0.495, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 10: train_acc=0.508, val_acc=0.496\n",
            "[Transformer-Parity] Epoch 11: train_acc=0.515, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 12: train_acc=0.498, val_acc=0.500\n",
            "[Transformer-Parity] Epoch 13: train_acc=0.514, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 14: train_acc=0.504, val_acc=0.489\n",
            "[Transformer-Parity] Epoch 15: train_acc=0.500, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 16: train_acc=0.501, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 17: train_acc=0.501, val_acc=0.489\n",
            "[Transformer-Parity] Epoch 18: train_acc=0.513, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 19: train_acc=0.509, val_acc=0.507\n",
            "[Transformer-Parity] Epoch 20: train_acc=0.510, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 21: train_acc=0.508, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 22: train_acc=0.498, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 23: train_acc=0.495, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 24: train_acc=0.495, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 25: train_acc=0.512, val_acc=0.504\n",
            "[Transformer-Parity] Epoch 26: train_acc=0.504, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 27: train_acc=0.520, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 28: train_acc=0.517, val_acc=0.487\n",
            "[Transformer-Parity] Epoch 29: train_acc=0.524, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 30: train_acc=0.500, val_acc=0.504\n",
            "[Transformer-Parity] Epoch 31: train_acc=0.509, val_acc=0.475\n",
            "[Transformer-Parity] Epoch 32: train_acc=0.522, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 33: train_acc=0.515, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 34: train_acc=0.517, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 35: train_acc=0.511, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 36: train_acc=0.512, val_acc=0.474\n",
            "[Transformer-Parity] Epoch 37: train_acc=0.501, val_acc=0.493\n",
            "[Transformer-Parity] Epoch 38: train_acc=0.525, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 39: train_acc=0.513, val_acc=0.489\n",
            "[Transformer-Parity] Epoch 40: train_acc=0.520, val_acc=0.479\n",
            "[Transformer-Parity] Epoch 41: train_acc=0.522, val_acc=0.491\n",
            "[Transformer-Parity] Epoch 42: train_acc=0.530, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 43: train_acc=0.521, val_acc=0.487\n",
            "[Transformer-Parity] Epoch 44: train_acc=0.526, val_acc=0.470\n",
            "[Transformer-Parity] Epoch 45: train_acc=0.520, val_acc=0.478\n",
            "[Transformer-Parity] Epoch 46: train_acc=0.514, val_acc=0.492\n",
            "[Transformer-Parity] Epoch 47: train_acc=0.518, val_acc=0.480\n",
            "[Transformer-Parity] Epoch 48: train_acc=0.533, val_acc=0.488\n",
            "[Transformer-Parity] Epoch 49: train_acc=0.520, val_acc=0.486\n",
            "[Transformer-Parity] Epoch 50: train_acc=0.526, val_acc=0.492\n",
            "[Transformer-Parity] Epoch 51: train_acc=0.528, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 52: train_acc=0.529, val_acc=0.492\n",
            "[Transformer-Parity] Epoch 53: train_acc=0.522, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 54: train_acc=0.526, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 55: train_acc=0.528, val_acc=0.479\n",
            "[Transformer-Parity] Epoch 56: train_acc=0.526, val_acc=0.481\n",
            "[Transformer-Parity] Epoch 57: train_acc=0.520, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 58: train_acc=0.523, val_acc=0.484\n",
            "[Transformer-Parity] Epoch 59: train_acc=0.533, val_acc=0.483\n",
            "[Transformer-Parity] Epoch 60: train_acc=0.522, val_acc=0.491\n",
            "[Transformer-Parity] Epoch 61: train_acc=0.523, val_acc=0.474\n",
            "[Transformer-Parity] Epoch 62: train_acc=0.532, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 63: train_acc=0.530, val_acc=0.480\n",
            "[Transformer-Parity] Epoch 64: train_acc=0.536, val_acc=0.478\n",
            "[Transformer-Parity] Epoch 65: train_acc=0.532, val_acc=0.491\n",
            "[Transformer-Parity] Epoch 66: train_acc=0.537, val_acc=0.492\n",
            "[Transformer-Parity] Epoch 67: train_acc=0.534, val_acc=0.491\n",
            "[Transformer-Parity] Epoch 68: train_acc=0.527, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 69: train_acc=0.535, val_acc=0.499\n",
            "[Transformer-Parity] Epoch 70: train_acc=0.533, val_acc=0.473\n",
            "[Transformer-Parity] Epoch 71: train_acc=0.529, val_acc=0.473\n",
            "[Transformer-Parity] Epoch 72: train_acc=0.534, val_acc=0.474\n",
            "[Transformer-Parity] Epoch 73: train_acc=0.528, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 74: train_acc=0.532, val_acc=0.482\n",
            "[Transformer-Parity] Epoch 75: train_acc=0.534, val_acc=0.489\n",
            "[Transformer-Parity] Epoch 76: train_acc=0.529, val_acc=0.475\n",
            "[Transformer-Parity] Epoch 77: train_acc=0.534, val_acc=0.483\n",
            "[Transformer-Parity] Epoch 78: train_acc=0.538, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 79: train_acc=0.531, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 80: train_acc=0.541, val_acc=0.478\n",
            "[Transformer-Parity] Epoch 81: train_acc=0.533, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 82: train_acc=0.531, val_acc=0.482\n",
            "[Transformer-Parity] Epoch 83: train_acc=0.542, val_acc=0.486\n",
            "[Transformer-Parity] Epoch 84: train_acc=0.532, val_acc=0.477\n",
            "[Transformer-Parity] Epoch 85: train_acc=0.538, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 86: train_acc=0.530, val_acc=0.464\n",
            "[Transformer-Parity] Epoch 87: train_acc=0.542, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 88: train_acc=0.533, val_acc=0.492\n",
            "[Transformer-Parity] Epoch 89: train_acc=0.544, val_acc=0.489\n",
            "[Transformer-Parity] Epoch 90: train_acc=0.539, val_acc=0.476\n",
            "[Transformer-Parity] Epoch 91: train_acc=0.537, val_acc=0.483\n",
            "[Transformer-Parity] Epoch 92: train_acc=0.542, val_acc=0.496\n",
            "[Transformer-Parity] Epoch 93: train_acc=0.540, val_acc=0.502\n",
            "[Transformer-Parity] Epoch 94: train_acc=0.538, val_acc=0.486\n",
            "[Transformer-Parity] Epoch 95: train_acc=0.548, val_acc=0.484\n",
            "[Transformer-Parity] Epoch 96: train_acc=0.537, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 97: train_acc=0.544, val_acc=0.479\n",
            "[Transformer-Parity] Epoch 98: train_acc=0.546, val_acc=0.487\n",
            "[Transformer-Parity] Epoch 99: train_acc=0.551, val_acc=0.503\n",
            "[Transformer-Parity] Epoch 100: train_acc=0.545, val_acc=0.470\n",
            "[Transformer-Parity] Epoch 101: train_acc=0.546, val_acc=0.482\n",
            "[Transformer-Parity] Epoch 102: train_acc=0.545, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 103: train_acc=0.546, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 104: train_acc=0.545, val_acc=0.482\n",
            "[Transformer-Parity] Epoch 105: train_acc=0.545, val_acc=0.478\n",
            "[Transformer-Parity] Epoch 106: train_acc=0.549, val_acc=0.484\n",
            "[Transformer-Parity] Epoch 107: train_acc=0.558, val_acc=0.485\n",
            "[Transformer-Parity] Epoch 108: train_acc=0.560, val_acc=0.483\n",
            "[Transformer-Parity] Epoch 109: train_acc=0.547, val_acc=0.478\n",
            "[Transformer-Parity] Epoch 110: train_acc=0.556, val_acc=0.481\n",
            "[Transformer-Parity] Epoch 111: train_acc=0.556, val_acc=0.477\n",
            "[Transformer-Parity] Epoch 112: train_acc=0.554, val_acc=0.481\n",
            "[Transformer-Parity] Epoch 113: train_acc=0.562, val_acc=0.483\n",
            "[Transformer-Parity] Epoch 114: train_acc=0.560, val_acc=0.491\n",
            "[Transformer-Parity] Epoch 115: train_acc=0.560, val_acc=0.474\n",
            "[Transformer-Parity] Epoch 116: train_acc=0.554, val_acc=0.476\n",
            "[Transformer-Parity] Epoch 117: train_acc=0.565, val_acc=0.493\n",
            "[Transformer-Parity] Epoch 118: train_acc=0.569, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 119: train_acc=0.561, val_acc=0.491\n",
            "[Transformer-Parity] Epoch 120: train_acc=0.565, val_acc=0.502\n",
            "[Transformer-Parity] Epoch 121: train_acc=0.571, val_acc=0.479\n",
            "[Transformer-Parity] Epoch 122: train_acc=0.570, val_acc=0.476\n",
            "[Transformer-Parity] Epoch 123: train_acc=0.566, val_acc=0.488\n",
            "[Transformer-Parity] Epoch 124: train_acc=0.561, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 125: train_acc=0.568, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 126: train_acc=0.565, val_acc=0.493\n",
            "[Transformer-Parity] Epoch 127: train_acc=0.578, val_acc=0.480\n",
            "[Transformer-Parity] Epoch 128: train_acc=0.580, val_acc=0.489\n",
            "[Transformer-Parity] Epoch 129: train_acc=0.576, val_acc=0.514\n",
            "[Transformer-Parity] Epoch 130: train_acc=0.573, val_acc=0.504\n",
            "[Transformer-Parity] Epoch 131: train_acc=0.579, val_acc=0.516\n",
            "[Transformer-Parity] Epoch 132: train_acc=0.586, val_acc=0.513\n",
            "[Transformer-Parity] Epoch 133: train_acc=0.584, val_acc=0.514\n",
            "[Transformer-Parity] Epoch 134: train_acc=0.582, val_acc=0.503\n",
            "[Transformer-Parity] Epoch 135: train_acc=0.595, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 136: train_acc=0.585, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 137: train_acc=0.585, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 138: train_acc=0.593, val_acc=0.530\n",
            "[Transformer-Parity] Epoch 139: train_acc=0.604, val_acc=0.514\n",
            "[Transformer-Parity] Epoch 140: train_acc=0.600, val_acc=0.523\n",
            "[Transformer-Parity] Epoch 141: train_acc=0.593, val_acc=0.507\n",
            "[Transformer-Parity] Epoch 142: train_acc=0.606, val_acc=0.514\n",
            "[Transformer-Parity] Epoch 143: train_acc=0.606, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 144: train_acc=0.608, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 145: train_acc=0.601, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 146: train_acc=0.604, val_acc=0.512\n",
            "[Transformer-Parity] Epoch 147: train_acc=0.612, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 148: train_acc=0.606, val_acc=0.517\n",
            "[Transformer-Parity] Epoch 149: train_acc=0.614, val_acc=0.534\n",
            "[Transformer-Parity] Epoch 150: train_acc=0.617, val_acc=0.524\n",
            "[Transformer-Parity] Epoch 151: train_acc=0.622, val_acc=0.516\n",
            "[Transformer-Parity] Epoch 152: train_acc=0.617, val_acc=0.513\n",
            "[Transformer-Parity] Epoch 153: train_acc=0.617, val_acc=0.508\n",
            "[Transformer-Parity] Epoch 154: train_acc=0.616, val_acc=0.524\n",
            "[Transformer-Parity] Epoch 155: train_acc=0.618, val_acc=0.512\n",
            "[Transformer-Parity] Epoch 156: train_acc=0.620, val_acc=0.523\n",
            "[Transformer-Parity] Epoch 157: train_acc=0.621, val_acc=0.510\n",
            "[Transformer-Parity] Epoch 158: train_acc=0.624, val_acc=0.525\n",
            "[Transformer-Parity] Epoch 159: train_acc=0.629, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 160: train_acc=0.629, val_acc=0.528\n",
            "[Transformer-Parity] Epoch 161: train_acc=0.634, val_acc=0.519\n",
            "[Transformer-Parity] Epoch 162: train_acc=0.632, val_acc=0.525\n",
            "[Transformer-Parity] Epoch 163: train_acc=0.630, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 164: train_acc=0.636, val_acc=0.524\n",
            "[Transformer-Parity] Epoch 165: train_acc=0.629, val_acc=0.512\n",
            "[Transformer-Parity] Epoch 166: train_acc=0.639, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 167: train_acc=0.639, val_acc=0.503\n",
            "[Transformer-Parity] Epoch 168: train_acc=0.633, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 169: train_acc=0.650, val_acc=0.513\n",
            "[Transformer-Parity] Epoch 170: train_acc=0.638, val_acc=0.503\n",
            "[Transformer-Parity] Epoch 171: train_acc=0.636, val_acc=0.520\n",
            "[Transformer-Parity] Epoch 172: train_acc=0.650, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 173: train_acc=0.644, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 174: train_acc=0.642, val_acc=0.524\n",
            "[Transformer-Parity] Epoch 175: train_acc=0.655, val_acc=0.504\n",
            "[Transformer-Parity] Epoch 176: train_acc=0.657, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 177: train_acc=0.658, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 178: train_acc=0.658, val_acc=0.507\n",
            "[Transformer-Parity] Epoch 179: train_acc=0.661, val_acc=0.514\n",
            "[Transformer-Parity] Epoch 180: train_acc=0.660, val_acc=0.513\n",
            "[Transformer-Parity] Epoch 181: train_acc=0.663, val_acc=0.500\n",
            "[Transformer-Parity] Epoch 182: train_acc=0.672, val_acc=0.520\n",
            "[Transformer-Parity] Epoch 183: train_acc=0.671, val_acc=0.490\n",
            "[Transformer-Parity] Epoch 184: train_acc=0.665, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 185: train_acc=0.680, val_acc=0.500\n",
            "[Transformer-Parity] Epoch 186: train_acc=0.666, val_acc=0.493\n",
            "[Transformer-Parity] Epoch 187: train_acc=0.660, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 188: train_acc=0.666, val_acc=0.499\n",
            "[Transformer-Parity] Epoch 189: train_acc=0.678, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 190: train_acc=0.670, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 191: train_acc=0.673, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 192: train_acc=0.684, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 193: train_acc=0.680, val_acc=0.503\n",
            "[Transformer-Parity] Epoch 194: train_acc=0.694, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 195: train_acc=0.675, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 196: train_acc=0.679, val_acc=0.500\n",
            "[Transformer-Parity] Epoch 197: train_acc=0.688, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 198: train_acc=0.689, val_acc=0.502\n",
            "[Transformer-Parity] Epoch 199: train_acc=0.683, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 200: train_acc=0.681, val_acc=0.512\n",
            "[Transformer-Parity] Epoch 201: train_acc=0.696, val_acc=0.523\n",
            "[Transformer-Parity] Epoch 202: train_acc=0.702, val_acc=0.502\n",
            "[Transformer-Parity] Epoch 203: train_acc=0.690, val_acc=0.496\n",
            "[Transformer-Parity] Epoch 204: train_acc=0.697, val_acc=0.513\n",
            "[Transformer-Parity] Epoch 205: train_acc=0.704, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 206: train_acc=0.702, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 207: train_acc=0.709, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 208: train_acc=0.697, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 209: train_acc=0.709, val_acc=0.487\n",
            "[Transformer-Parity] Epoch 210: train_acc=0.705, val_acc=0.494\n",
            "[Transformer-Parity] Epoch 211: train_acc=0.711, val_acc=0.523\n",
            "[Transformer-Parity] Epoch 212: train_acc=0.713, val_acc=0.498\n",
            "[Transformer-Parity] Epoch 213: train_acc=0.717, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 214: train_acc=0.720, val_acc=0.511\n",
            "[Transformer-Parity] Epoch 215: train_acc=0.713, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 216: train_acc=0.718, val_acc=0.515\n",
            "[Transformer-Parity] Epoch 217: train_acc=0.730, val_acc=0.495\n",
            "[Transformer-Parity] Epoch 218: train_acc=0.726, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 219: train_acc=0.714, val_acc=0.500\n",
            "[Transformer-Parity] Epoch 220: train_acc=0.727, val_acc=0.502\n",
            "[Transformer-Parity] Epoch 221: train_acc=0.724, val_acc=0.502\n",
            "[Transformer-Parity] Epoch 222: train_acc=0.725, val_acc=0.509\n",
            "[Transformer-Parity] Epoch 223: train_acc=0.741, val_acc=0.514\n",
            "[Transformer-Parity] Epoch 224: train_acc=0.739, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 225: train_acc=0.727, val_acc=0.511\n",
            "[Transformer-Parity] Epoch 226: train_acc=0.736, val_acc=0.519\n",
            "[Transformer-Parity] Epoch 227: train_acc=0.741, val_acc=0.488\n",
            "[Transformer-Parity] Epoch 228: train_acc=0.738, val_acc=0.517\n",
            "[Transformer-Parity] Epoch 229: train_acc=0.747, val_acc=0.496\n",
            "[Transformer-Parity] Epoch 230: train_acc=0.742, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 231: train_acc=0.737, val_acc=0.501\n",
            "[Transformer-Parity] Epoch 232: train_acc=0.738, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 233: train_acc=0.749, val_acc=0.496\n",
            "[Transformer-Parity] Epoch 234: train_acc=0.753, val_acc=0.499\n",
            "[Transformer-Parity] Epoch 235: train_acc=0.757, val_acc=0.497\n",
            "[Transformer-Parity] Epoch 236: train_acc=0.761, val_acc=0.506\n",
            "[Transformer-Parity] Epoch 237: train_acc=0.748, val_acc=0.496\n",
            "[Transformer-Parity] Epoch 238: train_acc=0.761, val_acc=0.517\n",
            "[Transformer-Parity] Epoch 239: train_acc=0.761, val_acc=0.512\n",
            "[Transformer-Parity] Epoch 240: train_acc=0.765, val_acc=0.507\n",
            "[Transformer-Parity] Epoch 241: train_acc=0.760, val_acc=0.507\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}