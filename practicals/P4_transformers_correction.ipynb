{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3db6482b",
      "metadata": {
        "id": "3db6482b"
      },
      "source": [
        "\n",
        "# Practical session n°4 :\n",
        "\n",
        "Notions:\n",
        "\n",
        "\n",
        "*   Attentional layers\n",
        "*   Multiple attentional heads\n",
        "*   Standard toy tasks (Dyck validaty test, addition, parity test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Part I — Presentation of the Transformer architecture\n",
        "\n",
        "In this part, you will:\n",
        "\n",
        "1. See how a tiny Transformer is coded in PyTorch.\n",
        "2. Focus on the attention layer: multi-head mechanism and the role of the Q, K, V matrices.\n",
        "3. Estimate how many FLOPs are involved in a forward pass through a multi-head attention layer\n",
        "   (and compare with the theoretical considerations from the lesson)."
      ],
      "metadata": {
        "id": "Q4iW-m0XrV7e"
      },
      "id": "Q4iW-m0XrV7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2bc8d855",
      "metadata": {
        "id": "2bc8d855"
      },
      "source": [
        "\n",
        "### **I.A.** Dyck-1 (balanced parentheses) dataset & validation target\n",
        "\n",
        "Goal: binary classification (valid vs invalid) of sequences over the alphabet `{ '(', ')' }`, with optional distractor tokens.\n",
        "- We'll generate balanced (valid) and corrupted (invalid) sequences of variable length.\n",
        "- Baselines: naive 1D CNN vs dilated CNN vs small Transformer.\n",
        "- Expectation: naive CNN struggles on long-range nesting; dilation helps; Transformer handles it cleanly.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CC1 — Imports & basic configuration\n",
        "\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(precision=4, sci_mode=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n"
      ],
      "metadata": {
        "id": "fZagGANXs-hI",
        "outputId": "73ad725d-08ec-4eab-afa4-4b8b9ef9198d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fZagGANXs-hI",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CC2 — Tiny Transformer building blocks (embedding + multi-head attention)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 1024):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
        "            * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, D)\n",
        "        L = x.size(1)\n",
        "        return x + self.pe[:, :L, :]\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Minimal multi-head self-attention.\n",
        "    If verbose=True, prints tensor shapes at key steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int = 64, n_heads: int = 4, verbose: bool = False):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_head = d_model // n_heads\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.Wq = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wk = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wv = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wo = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def _vprint(self, name, x):\n",
        "        if self.verbose:\n",
        "            print(f\"{name}: {tuple(x.shape)}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, D)\n",
        "        B, L, D = x.shape\n",
        "\n",
        "        Q = self.Wq(x)  # (B, L, D)\n",
        "        K = self.Wk(x)\n",
        "        V = self.Wv(x)\n",
        "        self._vprint(\"Q\", Q)\n",
        "        self._vprint(\"K\", K)\n",
        "        self._vprint(\"V\", V)\n",
        "\n",
        "        # reshape to heads\n",
        "        Q = Q.view(B, L, self.n_heads, self.d_head).transpose(1, 2)  # (B, H, L, Dh)\n",
        "        K = K.view(B, L, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        V = V.view(B, L, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        self._vprint(\"Q_heads\", Q)\n",
        "        self._vprint(\"K_heads\", K)\n",
        "        self._vprint(\"V_heads\", V)\n",
        "\n",
        "        # scaled dot-product attention\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_head)  # (B,H,L,L)\n",
        "        self._vprint(\"scores\", scores)\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)  # (B,H,L,L)\n",
        "        self._vprint(\"attn_probs\", attn)\n",
        "\n",
        "        Z = torch.matmul(attn, V)  # (B,H,L,Dh)\n",
        "        self._vprint(\"Z_heads\", Z)\n",
        "\n",
        "        # merge heads\n",
        "        Z = Z.transpose(1, 2).contiguous().view(B, L, D)  # (B, L, D)\n",
        "        self._vprint(\"Z_merged\", Z)\n",
        "\n",
        "        out = self.Wo(Z)  # (B, L, D)\n",
        "        self._vprint(\"out\", out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model: int = 64, n_heads: int = 4, mlp_ratio: int = 4):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadSelfAttention(d_model=d_model, n_heads=n_heads, verbose=False)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * mlp_ratio),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_model * mlp_ratio, d_model),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class TinyTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Tiny Transformer for sequence classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int, d_model: int = 64, n_heads: int = 4, n_layers: int = 2, num_classes: int = 2):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding(d_model)\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [TransformerBlock(d_model=d_model, n_heads=n_heads) for _ in range(n_layers)]\n",
        "        )\n",
        "        self.head = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L) token ids\n",
        "        h = self.tok_emb(x)\n",
        "        h = self.pos_emb(h)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        # use mean pooling for classification\n",
        "        h = h.mean(dim=1)\n",
        "        return self.head(h)\n"
      ],
      "metadata": {
        "id": "N_ikSjeMtBUt"
      },
      "id": "N_ikSjeMtBUt",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 1 — Check embedding output size\n",
        "\n",
        "Using `TinyTransformer`, define a random input batch of token ids with:\n",
        "\n",
        "- batch size `B`\n",
        "- sequence length `L`\n",
        "- vocabulary size consistent with the model\n",
        "\n",
        "Use `torch.randint` to generate this input and pass it **only through the embedding layer**.  \n",
        "Verify that the output has shape `(B, L, d_model)`."
      ],
      "metadata": {
        "id": "TgJt9nGgtUcs"
      },
      "id": "TgJt9nGgtUcs"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC3 — Correction Exercice 1\n",
        "\n",
        "B, L = 4, 10\n",
        "vocab_size = 20\n",
        "d_model = 64\n",
        "\n",
        "model = TinyTransformer(vocab_size=vocab_size, d_model=d_model, n_heads=4, n_layers=2, num_classes=2)\n",
        "\n",
        "x = torch.randint(low=0, high=vocab_size, size=(B, L))  # (B, L)\n",
        "with torch.no_grad():\n",
        "    emb_out = model.tok_emb(x)  # (B, L, d_model)\n",
        "\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Embedding output shape:\", emb_out.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "mhgeyjsitI6p",
        "outputId": "cf540b20-8b52-4350-a717-45eaef7999b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mhgeyjsitI6p",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 10])\n",
            "Embedding output shape: torch.Size([4, 10, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 2 — Pass through MultiHeadSelfAttention (with verbose shapes)\n",
        "\n",
        "1. Reuse the embedded tensor from Exercice 1 (or recreate it).\n",
        "2. Instantiate a `MultiHeadSelfAttention` layer with `verbose=True`.\n",
        "3. Pass the embeddings through it and observe the printed shapes at each step.\n",
        "\n",
        "This is to **trace Q, K, V, heads, scores, and outputs**.\n"
      ],
      "metadata": {
        "id": "cPcdxu-CtgEh"
      },
      "id": "cPcdxu-CtgEh"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC4 — Correction Exercice 2\n",
        "\n",
        "B, L = 2, 6\n",
        "vocab_size = 20\n",
        "d_model = 64\n",
        "n_heads = 4\n",
        "\n",
        "x = torch.randint(0, vocab_size, (B, L))\n",
        "emb = model.tok_emb(x)\n",
        "\n",
        "attn = MultiHeadSelfAttention(d_model=d_model, n_heads=n_heads, verbose=True)\n",
        "with torch.no_grad():\n",
        "    out = attn(emb)\n",
        "\n",
        "print(\"Final attention output shape:\", out.shape)\n"
      ],
      "metadata": {
        "id": "lGzvX2I0tSVM",
        "outputId": "02bdb2d9-2947-4a25-df1f-e2ad8e295abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lGzvX2I0tSVM",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: (2, 6, 64)\n",
            "K: (2, 6, 64)\n",
            "V: (2, 6, 64)\n",
            "Q_heads: (2, 4, 6, 16)\n",
            "K_heads: (2, 4, 6, 16)\n",
            "V_heads: (2, 4, 6, 16)\n",
            "scores: (2, 4, 6, 6)\n",
            "attn_probs: (2, 4, 6, 6)\n",
            "Z_heads: (2, 4, 6, 16)\n",
            "Z_merged: (2, 6, 64)\n",
            "out: (2, 6, 64)\n",
            "Final attention output shape: torch.Size([2, 6, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 3 — Count FLOPs in multi-head self-attention\n",
        "\n",
        "For a single multi-head self-attention layer with:\n",
        "\n",
        "- sequence length `L`\n",
        "- model dimension `d_model`\n",
        "- number of heads `h` (each of size `d_head = d_model / h`)\n",
        "\n",
        "1. Derive the approximate number of multiply-add operations for:\n",
        "   - Q, K, V linear projections\n",
        "   - Attention scores computation\n",
        "   - Attention-weighted sum\n",
        "   - Output projection\n",
        "2. Identify the term that dominates when `L` is large, and explain why it is in `O(L² × d_model)`.\n",
        "\n",
        "Complete the function below.\n"
      ],
      "metadata": {
        "id": "7K_D-zOFtvlx"
      },
      "id": "7K_D-zOFtvlx"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC5 — Correction Exercice 3 & 4 — FLOPs estimates\n",
        "\n",
        "def mhsa_flops(L, d_model, n_heads):\n",
        "    \"\"\"\n",
        "    Rough FLOPs (multiply-adds counted as ~2 ops, but we keep a simple count).\n",
        "    Returns a dict with contributions.\n",
        "    \"\"\"\n",
        "    d_head = d_model // n_heads\n",
        "\n",
        "    # Q, K, V projections: 3 * (L * d_model * d_model)\n",
        "    qkv = 3 * L * d_model * d_model\n",
        "\n",
        "    # scores = Q K^T: (B,H,L,Dh) x (B,H,Dh,L) -> (B,H,L,L)\n",
        "    # ~ 2 * (H * L * L * Dh)\n",
        "    scores = 2 * n_heads * (L * L * d_head)\n",
        "\n",
        "    # attn @ V: (B,H,L,L) x (B,H,L,Dh) -> (B,H,L,Dh)\n",
        "    # ~ 2 * (H * L * L * Dh)\n",
        "    weighted = 2 * n_heads * (L * L * d_head)\n",
        "\n",
        "    # output projection Wo: L * d_model * d_model\n",
        "    wo = L * d_model * d_model\n",
        "\n",
        "    return {\n",
        "        \"qkv\": qkv,\n",
        "        \"scores\": scores,\n",
        "        \"weighted\": weighted,\n",
        "        \"wo\": wo,\n",
        "        \"total\": qkv + scores + weighted + wo,\n",
        "    }\n",
        "\n",
        "# Example: impact of L (show domination of L^2 * d_model terms)\n",
        "for L in [16, 64, 256]:\n",
        "    stats = mhsa_flops(L=L, d_model=64, n_heads=4)\n",
        "    print(f\"L={L} -> total={stats['total']:.2e}, scores+weighted={stats['scores']+stats['weighted']:.2e}\")\n",
        "\n",
        "print(\"\\nObservation: for large L, the attention matrix computations (in L^2) dominate.\")\n",
        "\n",
        "# Exercice 4 — Example: FLOPs for a tiny Transformer on a batch\n",
        "def tiny_transformer_flops(num_layers, L, d_model, n_heads, mlp_ratio=4):\n",
        "    attn = mhsa_flops(L, d_model, n_heads)[\"total\"]\n",
        "    # MLP per layer: 2 linear layers: ~ 2 * L * d_model * (d_model * mlp_ratio)\n",
        "    mlp = 2 * L * d_model * (d_model * mlp_ratio)\n",
        "    per_layer = attn + mlp\n",
        "    return num_layers * per_layer\n",
        "\n",
        "print(\"\\nTinyTransformer example (num_layers=2, L=64, d_model=64, n_heads=4):\")\n",
        "print(f\"~ {tiny_transformer_flops(2, 64, 64, 4):.2e} FLOPs (rough order of magnitude)\")\n"
      ],
      "metadata": {
        "id": "TQL1gdEPt3rH",
        "outputId": "9d23e9d5-fe5c-4aed-f904-c65e8211593a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TQL1gdEPt3rH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L=16 -> total=3.28e+05, scores+weighted=6.55e+04\n",
            "L=64 -> total=2.10e+06, scores+weighted=1.05e+06\n",
            "L=256 -> total=2.10e+07, scores+weighted=1.68e+07\n",
            "\n",
            "Observation: for large L, the attention matrix computations (in L^2) dominate.\n",
            "\n",
            "TinyTransformer example (num_layers=2, L=64, d_model=64, n_heads=4):\n",
            "~ 8.39e+06 FLOPs (rough order of magnitude)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II — A first example: Validation of Dyck-1 words\n",
        "\n",
        "We now train models to decide if a word over `{ '(', ')' }` is a valid Dyck-1 word (balanced parentheses).\n",
        "\n",
        "We start with a simple dataset **without distractors**.\n"
      ],
      "metadata": {
        "id": "v335uURwuFUX"
      },
      "id": "v335uURwuFUX"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC6 — Dyck-1 dataset (no distractors)\n",
        "\n",
        "VOCAB_DYCK = ['(', ')']\n",
        "stoi_dyck = {c: i for i, c in enumerate(VOCAB_DYCK)}\n",
        "itos_dyck = {i: c for c, i in stoi_dyck.items()}\n",
        "\n",
        "def dyck1_valid_sequence(n_pairs):\n",
        "    \"\"\"\n",
        "    Generate a uniformly random valid Dyck-1 sequence with n_pairs pairs.\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    depth = 0\n",
        "    for _ in range(2 * n_pairs):\n",
        "        if depth == 0:\n",
        "            seq.append('(')\n",
        "            depth += 1\n",
        "        elif depth == (2 * n_pairs - len(seq)):\n",
        "            seq.append(')')\n",
        "            depth -= 1\n",
        "        else:\n",
        "            if random.random() < 0.5:\n",
        "                seq.append('(')\n",
        "                depth += 1\n",
        "            else:\n",
        "                seq.append(')')\n",
        "                depth -= 1\n",
        "    return ''.join(seq)\n",
        "\n",
        "def is_valid_dyck1(s):\n",
        "    depth = 0\n",
        "    for ch in s:\n",
        "        if ch == '(':\n",
        "            depth += 1\n",
        "        elif ch == ')':\n",
        "            depth -= 1\n",
        "        if depth < 0:\n",
        "            return False\n",
        "    return depth == 0\n",
        "\n",
        "class DyckDataset(nn.Module):\n",
        "    \"\"\"\n",
        "    Binary classification:\n",
        "    y = 1 if valid Dyck-1, y = 0 otherwise.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_samples=2000, n_pairs=6):\n",
        "        super().__init__()\n",
        "        self.samples = []\n",
        "        for _ in range(n_samples):\n",
        "            s = dyck1_valid_sequence(n_pairs)\n",
        "            # with prob 0.5 corrupt one char to create invalid string\n",
        "            if random.random() < 0.5:\n",
        "                y = 1\n",
        "            else:\n",
        "                s = list(s)\n",
        "                pos = random.randrange(len(s))\n",
        "                s[pos] = '(' if s[pos] == ')' else ')'\n",
        "                s = ''.join(s)\n",
        "                y = int(is_valid_dyck1(s))\n",
        "                # if by chance it is valid, flip again\n",
        "                if y == 1:\n",
        "                    pos = (pos + 1) % len(s)\n",
        "                    s = list(s)\n",
        "                    s[pos] = '(' if s[pos] == ')' else ')'\n",
        "                    s = ''.join(s)\n",
        "                    y = int(is_valid_dyck1(s))\n",
        "            x = torch.tensor([stoi_dyck[c] for c in s], dtype=torch.long)\n",
        "            self.samples.append((x, torch.tensor(y, dtype=torch.long)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "def dyck_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    L = max(len(x) for x in xs)\n",
        "    X = torch.full((len(xs), L), fill_value=0, dtype=torch.long)\n",
        "    for i, x in enumerate(xs):\n",
        "        X[i, :len(x)] = x\n",
        "    Y = torch.stack(ys)\n",
        "    return X, Y\n"
      ],
      "metadata": {
        "id": "TN2FJTOGuLYY"
      },
      "id": "TN2FJTOGuLYY",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 5 — Inspect Dyck-1 samples\n",
        "\n",
        "1. Build a `DyckDataset` with `n_pairs = 6`.\n",
        "2. Print the first 5 sequences:\n",
        "   - as indices\n",
        "   - as corresponding parenthesis strings\n",
        "   - with their labels (valid / invalid)\n",
        "3. What is the size of the vocabulary for this problem?\n"
      ],
      "metadata": {
        "id": "qGyMFcCeunqR"
      },
      "id": "qGyMFcCeunqR"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC7 — Correction Exercice 5\n",
        "\n",
        "dyck_train = DyckDataset(n_samples=8, n_pairs=6)\n",
        "\n",
        "for i in range(5):\n",
        "    x, y = dyck_train[i]\n",
        "    s = ''.join(itos_dyck[int(t)] for t in x)\n",
        "    print(f\"Sample {i}: indices={x.tolist()}  | word={s}  | label={int(y)}\")\n",
        "\n",
        "print(\"\\nVocabulary:\", VOCAB_DYCK)\n",
        "print(\"Vocab size:\", len(VOCAB_DYCK))\n"
      ],
      "metadata": {
        "id": "OEkcsYYKupbc",
        "outputId": "972fe7b9-6bc1-4a53-eb60-46e6501485a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OEkcsYYKupbc",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0: indices=[0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1]  | word=()())(()()))  | label=0\n",
            "Sample 1: indices=[0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]  | word=()(()((())))  | label=1\n",
            "Sample 2: indices=[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  | word=()()()()()()  | label=1\n",
            "Sample 3: indices=[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1]  | word=((((()(())))  | label=0\n",
            "Sample 4: indices=[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]  | word=()(()(()(())  | label=0\n",
            "\n",
            "Vocabulary: ['(', ')']\n",
            "Vocab size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 6 — Training loop with history + learning curves\n",
        "\n",
        "Complete a training loop that:\n",
        "\n",
        "1. Trains a small Transformer on Dyck-1.\n",
        "2. Stores training and validation accuracies at each epoch.\n",
        "3. Plots both curves on the same figure.\n",
        "\n",
        "Use the `TinyTransformer` from Part I (with `vocab_size = 2`).\n"
      ],
      "metadata": {
        "id": "hBv9HwK0uwXl"
      },
      "id": "hBv9HwK0uwXl"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC8 — Training utilities (Transformer on Dyck-1) with history\n",
        "\n",
        "def accuracy_from_logits(logits, y):\n",
        "    return (logits.argmax(dim=-1) == y).float().mean().item()\n",
        "\n",
        "def train_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "    for X, Y in loader:\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X)\n",
        "        loss = F.cross_entropy(logits, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        bs = X.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += accuracy_from_logits(logits, Y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "    for X, Y in loader:\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        logits = model(X)\n",
        "        loss = F.cross_entropy(logits, Y)\n",
        "        bs = X.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += accuracy_from_logits(logits, Y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_acc / n\n"
      ],
      "metadata": {
        "id": "U76FkXdku1XZ"
      },
      "id": "U76FkXdku1XZ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Transformer on Dyck-1 and plot curves\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = DyckDataset(n_samples=2000, n_pairs=6)\n",
        "val_set   = DyckDataset(n_samples=500,  n_pairs=6)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, collate_fn=dyck_collate)\n",
        "val_loader   = DataLoader(val_set,   batch_size=64, shuffle=False, collate_fn=dyck_collate)\n",
        "\n",
        "model_tx = TinyTransformer(vocab_size=len(VOCAB_DYCK), d_model=64, n_heads=4, n_layers=2, num_classes=2).to(device)\n",
        "opt = torch.optim.AdamW(model_tx.parameters(), lr=2e-3)\n",
        "\n",
        "E = 8\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(1, E+1):\n",
        "    tr_loss, tr_acc = train_epoch(model_tx, train_loader, opt)\n",
        "    va_loss, va_acc = eval_epoch(model_tx, val_loader)\n",
        "    train_accs.append(tr_acc)\n",
        "    val_accs.append(va_acc)\n",
        "    print(f\"Epoch {epoch}: train_acc={tr_acc:.3f}, val_acc={va_acc:.3f}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, E+1), train_accs, label=\"train\")\n",
        "plt.plot(range(1, E+1), val_accs, label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Dyck-1 — TinyTransformer\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hct-feEqu5fN",
        "outputId": "c22463ff-a29d-4edd-8791-dd7abefe7cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "id": "Hct-feEqu5fN",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_acc=0.502, val_acc=0.508\n",
            "Epoch 2: train_acc=0.506, val_acc=0.508\n",
            "Epoch 3: train_acc=0.608, val_acc=0.844\n",
            "Epoch 4: train_acc=0.989, val_acc=1.000\n",
            "Epoch 5: train_acc=1.000, val_acc=1.000\n",
            "Epoch 6: train_acc=1.000, val_acc=1.000\n",
            "Epoch 7: train_acc=1.000, val_acc=1.000\n",
            "Epoch 8: train_acc=1.000, val_acc=1.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 7 — Compare with a CNN baseline\n",
        "\n",
        "1. Implement a 1D CNN similar to the one used for MNIST (convolutions + non-linearities + pooling / global pooling).\n",
        "2. Train it on the same Dyck-1 dataset.\n",
        "3. Compare its validation accuracy and behavior with the Transformer.\n",
        "\n",
        "Use the correction cell below only after you have tried.\n"
      ],
      "metadata": {
        "id": "hnDzwsjxvIpI"
      },
      "id": "hnDzwsjxvIpI"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC10 — Correction Exercice 7 — Simple CNN baseline on Dyck-1\n",
        "\n",
        "class DyckCNN(nn.Module):\n",
        "    def __init__(self, vocab_size=2, emb_dim=32, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.conv1 = nn.Conv1d(emb_dim, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.head = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L)\n",
        "        e = self.emb(x).transpose(1, 2)  # (B,C,L)\n",
        "        h = F.relu(self.conv1(e))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = h.mean(dim=-1)               # global average pooling\n",
        "        return self.head(h)\n",
        "\n",
        "cnn = DyckCNN(vocab_size=len(VOCAB_DYCK), emb_dim=32, num_classes=2).to(device)\n",
        "opt_cnn = torch.optim.AdamW(cnn.parameters(), lr=2e-3)\n",
        "\n",
        "E = 8\n",
        "for epoch in range(1, E+1):\n",
        "    tr_loss, tr_acc = train_epoch(cnn, train_loader, opt_cnn)\n",
        "    va_loss, va_acc = eval_epoch(cnn, val_loader)\n",
        "    print(f\"[CNN] Epoch {epoch}: train_acc={tr_acc:.3f}, val_acc={va_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "Y-aVL-3VvIC9",
        "outputId": "c66f9690-c120-446e-a7ac-47a8f1c1718c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Y-aVL-3VvIC9",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CNN] Epoch 1: train_acc=0.524, val_acc=0.508\n",
            "[CNN] Epoch 2: train_acc=0.525, val_acc=0.534\n",
            "[CNN] Epoch 3: train_acc=0.565, val_acc=0.548\n",
            "[CNN] Epoch 4: train_acc=0.604, val_acc=0.588\n",
            "[CNN] Epoch 5: train_acc=0.609, val_acc=0.608\n",
            "[CNN] Epoch 6: train_acc=0.640, val_acc=0.648\n",
            "[CNN] Epoch 7: train_acc=0.653, val_acc=0.622\n",
            "[CNN] Epoch 8: train_acc=0.653, val_acc=0.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part III — Addition and Parity tasks\n",
        "\n",
        "### Exercice 11\n",
        "\n",
        "Use the following synthetic datasets to train and compare models\n",
        "(Transformers and CNNs) on:\n",
        "\n",
        "1. **Addition**: predict the last digit of `a + b` from an input like `\"123+45=\"`.\n",
        "2. **Parity**: predict the parity (0/1) of a binary string.\n",
        "\n",
        "Reuse your training utilities from Part II.\n"
      ],
      "metadata": {
        "id": "dL_O3f55vTXv"
      },
      "id": "dL_O3f55vTXv"
    },
    {
      "cell_type": "code",
      "source": [
        "# CC11 — Addition & Parity datasets\n",
        "\n",
        "# --- Addition ---\n",
        "DIGITS = [str(i) for i in range(10)]\n",
        "ADD_VOCAB = DIGITS + ['+', '=']\n",
        "add_stoi = {c: i for i, c in enumerate(ADD_VOCAB)}\n",
        "\n",
        "def gen_add_sample(n1_digits=3, n2_digits=3):\n",
        "    \"\"\"\n",
        "    Input:  string representation \"a+b=\".\n",
        "    Target: last digit of (a + b).\n",
        "    \"\"\"\n",
        "    a = random.randint(0, 10**n1_digits - 1)\n",
        "    b = random.randint(0, 10**n2_digits - 1)\n",
        "    s = f\"{a}+{b}=\"\n",
        "    x = torch.tensor([add_stoi[c] for c in s], dtype=torch.long)\n",
        "    y = (a + b) % 10\n",
        "    return x, torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class AddDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, n, n1_digits=3, n2_digits=3):\n",
        "        self.samples = [gen_add_sample(n1_digits, n2_digits) for _ in range(n)]\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i): return self.samples[i]\n",
        "\n",
        "def add_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    L = max(len(x) for x in xs)\n",
        "    X = torch.full((len(xs), L), fill_value=0, dtype=torch.long)\n",
        "    for i, x in enumerate(xs):\n",
        "        X[i, :len(x)] = x\n",
        "    Y = torch.stack(ys)\n",
        "    return X, Y\n",
        "\n",
        "# --- Parity ---\n",
        "BIN_VOCAB = ['0', '1']\n",
        "bin_stoi = {c: i for i, c in enumerate(BIN_VOCAB)}\n",
        "\n",
        "def gen_parity_sample(L=32):\n",
        "    \"\"\"\n",
        "    Input:  random binary string of length L.\n",
        "    Target: parity of number of '1's (0 = even, 1 = odd).\n",
        "    \"\"\"\n",
        "    s = ''.join(random.choice(BIN_VOCAB) for _ in range(L))\n",
        "    x = torch.tensor([bin_stoi[c] for c in s], dtype=torch.long)\n",
        "    y = s.count('1') % 2\n",
        "    return x, torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class ParityDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, n, L=32):\n",
        "        self.samples = [gen_parity_sample(L) for _ in range(n)]\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i): return self.samples[i]\n",
        "\n",
        "def parity_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    L = max(len(x) for x in xs)\n",
        "    X = torch.full((len(xs), L), fill_value=0, dtype=torch.long)\n",
        "    for i, x in enumerate(xs):\n",
        "        X[i, :len(x)] = x\n",
        "    Y = torch.stack(ys)\n",
        "    return X, Y\n"
      ],
      "metadata": {
        "id": "HjFRFST-vWzS"
      },
      "id": "HjFRFST-vWzS",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CC12 — Reusable training helper (supports different num_classes)\n",
        "\n",
        "def train_model_classifier(model, train_loader, val_loader, epochs=6, lr=2e-3, name=\"model\"):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    best_val = 0.0\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        tr_loss, tr_acc = train_epoch(model, train_loader, opt)\n",
        "        va_loss, va_acc = eval_epoch(model, val_loader)\n",
        "        if va_acc > best_val:\n",
        "            best_val = va_acc\n",
        "        print(f\"[{name}] Epoch {ep}: train_acc={tr_acc:.3f}, val_acc={va_acc:.3f}\")\n",
        "    print(f\"[{name}] best_val_acc={best_val:.3f}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "l77JtPjXvcbK"
      },
      "id": "l77JtPjXvcbK",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CC13 — Example usage: TinyTransformer on Addition & Parity\n",
        "\n",
        "# Addition\n",
        "train_add = AddDataset(n=4000)\n",
        "val_add   = AddDataset(n=1000)\n",
        "\n",
        "train_add_loader = torch.utils.data.DataLoader(train_add, batch_size=64, shuffle=True,  collate_fn=add_collate)\n",
        "val_add_loader   = torch.utils.data.DataLoader(val_add,   batch_size=64, shuffle=False, collate_fn=add_collate)\n",
        "\n",
        "tx_add = TinyTransformer(vocab_size=len(ADD_VOCAB), d_model=64, n_heads=4, n_layers=2, num_classes=10)\n",
        "train_model_classifier(tx_add, train_add_loader, val_add_loader, epochs=6, name=\"Transformer-Add\")\n",
        "\n",
        "# Parity\n",
        "train_par = ParityDataset(n=4000, L=64)\n",
        "val_par   = ParityDataset(n=1000, L=64)\n",
        "\n",
        "train_par_loader = torch.utils.data.DataLoader(train_par, batch_size=64, shuffle=True,  collate_fn=parity_collate)\n",
        "val_par_loader   = torch.utils.data.DataLoader(val_par,   batch_size=64, shuffle=False, collate_fn=parity_collate)\n",
        "\n",
        "tx_par = TinyTransformer(vocab_size=len(BIN_VOCAB), d_model=64, n_heads=4, n_layers=2, num_classes=2)\n",
        "train_model_classifier(tx_par, train_par_loader, val_par_loader, epochs=6, name=\"Transformer-Parity\")\n"
      ],
      "metadata": {
        "id": "dVUFh8pxvgkd",
        "outputId": "8e6426b9-e1f4-43c4-8d36-7cddc039f654",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dVUFh8pxvgkd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Transformer-Add] Epoch 1: train_acc=0.114, val_acc=0.132\n",
            "[Transformer-Add] Epoch 2: train_acc=0.125, val_acc=0.140\n",
            "[Transformer-Add] Epoch 3: train_acc=0.164, val_acc=0.154\n",
            "[Transformer-Add] Epoch 4: train_acc=0.188, val_acc=0.165\n",
            "[Transformer-Add] Epoch 5: train_acc=0.261, val_acc=0.259\n",
            "[Transformer-Add] Epoch 6: train_acc=0.498, val_acc=0.647\n",
            "[Transformer-Add] best_val_acc=0.647\n",
            "[Transformer-Parity] Epoch 1: train_acc=0.506, val_acc=0.511\n",
            "[Transformer-Parity] Epoch 2: train_acc=0.493, val_acc=0.505\n",
            "[Transformer-Parity] Epoch 3: train_acc=0.509, val_acc=0.484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GaOhBhUJvR49"
      },
      "id": "GaOhBhUJvR49"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3iOGskOwuCYH"
      },
      "id": "3iOGskOwuCYH"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xB2AJYzUtmXp"
      },
      "id": "xB2AJYzUtmXp"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}