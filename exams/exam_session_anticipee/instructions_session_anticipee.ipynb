{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Consignes\n",
        "\n",
        "Cet énoncé vous est destiné à tous les trois. Les deux problèmes qu'il comporte sont entièrement construits à partir des TP réalisés ensemble. Les deux exercices sont des classiques.\n",
        "Vous avez, comme déjà dit, droit à toute la matière que vous souhaitez (chatbots, notes personnelles, corrigés des TPs). \\\n",
        "À la fin de l'examen, vous enverrez à l'adresse tpdeeplearning@gmail.com une archive .tar contenant un notebook par problème et par exercice (soit quatre notebooks au maximum).\n",
        "\n",
        "Vous serez évalués sur les points suivants:\n",
        "\n",
        "- La rédaction.\\\n",
        "Présentez votre approche. En particulier, si vous utilisez un chatbot (ce que je recommande), vous pouvez simplement copier les prompts que vous utilisez dans des cellules du notebook tout en mettant en avant votre esprit critique (par exemple, en commentant les réponses fournies par la machine). Dans tous les cas, notez que c'est la qualité de votre production qui sera jugée avant tout. Il n'est donc pas primordial d'avoir été jusqu'au bout de l'énoncé.\n",
        "\n",
        "- La propreté des notebooks.\\\n",
        "Ils doivent être organisés et faciles à lire. Je dois pouvoir faire tourner le code sans problème et en comprendre les éléments. Il faut donc commenter un minimum.\n"
      ],
      "metadata": {
        "id": "Ikh-ycISIplN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvaKH1dZvg2B"
      },
      "source": [
        "# Problème n°1 (1h)\n",
        "\n",
        "Dans ce problème, il s'agit de tester une parade à l'imperfection des résultats au TP n°5, partie 2.\n",
        "\n",
        "- Refaire tourner le code solution du TP°5 (avec deux échantillons de bruit noise et noise2 additionnels) en stockant les poids du réseau au bout de 40 époques.\n",
        "\n",
        "- Pouvez-vous rappeler le défaut qui avait été observé dans la question 2 ?\n",
        "  Ré-expliquez son origine en terme de médiane conditionnelle.\n",
        "\n",
        "- Nous avons évoqué plusieurs parades. La première consiste simplement à ajouter un nouvel échantillon de bruit (noise3). Faites une expérience sur quarante époques. Procédez ensuite à une comparaison qualitative avec les sorties du  modèle précédent. Faites enfin une comparaison quantitative (limitée) à partir des images ne contenant que du bruit.\n",
        "\n",
        "- Nous avons aussi évoqué la régression quantile. Pouvez-vous expliquer en quoi cette forme de régression est adaptée ? Faites une expérience sur quarante époque en visant le quantile d'ordre 0.4 (dans la configuration initiale, c'est à dire avec deux échantillons de bruit seulement). Le problème est-il parfaitement résolu ? Comme ci-dessus, vérifier de manière qualitative et quantitative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problème n°2 (1h)\n",
        "\n",
        " Dans le TP n°4 sur les transformers, nous avons appris à un modèle à préciser la parité d'une suite de zéros et de uns. Vous devez :\n",
        "- reprendre le transformer proposé et le faire converger sur des suites de taille 64.\n",
        "- définir un CNN pour la classification binaire dont le champ réceptif est proche de 32 comportant trois couches de convolution et deux couches complètement connectées.\n",
        "- comparer les courbes d'apprentissage du CNN et du transformer (finesse sur le jeu de validation)\n",
        "- comparer le nombre de poids dans chacun des modèles\n",
        "- conclure"
      ],
      "metadata": {
        "id": "ey-WEaX9jShi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice n°1 (1/2 h)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GtHsjQMLjdBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le modèle ci-dessous, pouvez-vous préciser :\n",
        "- la taille du champ réceptif associé à un pixel d'une carte de caractéristique en sortie de enc2, par un calcul théorique.\n",
        "- par une démarche empirique simple, la taille du champ réceptif associé à un pixel en sortie.\n"
      ],
      "metadata": {
        "id": "PozMKR6Ggit1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyNN(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=1, base=16):\n",
        "        super().__init__()\n",
        "\n",
        "        # 2 Conv2D\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, base, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(base, base, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # 2 Conv2D, first with stride=2\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(base, base * 2, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(base * 2, base * 2, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # again 2 Conv2D, first with stride=2\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(base * 2, base * 4, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(base * 4, base * 4, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # alternance Conv2D / ConvTranspose2D\n",
        "        self.mid = nn.Conv2d(base * 4, base * 4, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(base * 4, base * 2, kernel_size=2, stride=2, bias=False)\n",
        "        self.dec1 = nn.Conv2d(base * 2, base * 2, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(base * 2, base, kernel_size=2, stride=2, bias=False)\n",
        "        self.dec2 = nn.Conv2d(base, base, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.head = nn.Conv2d(base, out_ch, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.enc1(x)\n",
        "        x = self.enc2(x)\n",
        "        x = self.enc3(x)\n",
        "\n",
        "        x = torch.relu(self.mid(x))\n",
        "\n",
        "        x = self.up1(x)\n",
        "        x = torch.relu(self.dec1(x))\n",
        "\n",
        "        x = self.up2(x)\n",
        "        x = torch.relu(self.dec2(x))\n",
        "\n",
        "        return self.head(x)"
      ],
      "metadata": {
        "id": "XYgIVJ4ZgWiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xdmiM80hy1Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice n°2 (1/2 h)\n",
        "\n"
      ],
      "metadata": {
        "id": "eoxhhb1Aju-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Charger le Visual Transformer (DeiT) hébergé sur Hugging Face à l'adresse :\n",
        "\"facebook/deit-tiny-patch16-224\".\n",
        "- Comment l'image est-elle transformée en séquence de vecteurs dans ce modèle ?\n",
        "- Quelle est la taille de l'espace latent ?\n",
        "- Quelle est la signification du premier token ?\n",
        "- Classifier l'image fournie dans le TP n°2 (le chat) à l'aide de ce modèle (montrer les cinq premières classes choisies)\n",
        "- Visualiser les scores attentionnels associés au premier token pour les trois premières têtes de la première couche attentionnelle. Certaines sont-elles interprétables ?"
      ],
      "metadata": {
        "id": "3d2kBCzyjqUl"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}